{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ejercicio 3 : Preprocesamiento\n## Objetivo de la práctica\n1. Comprender y aplicar normalización, tokenización, stopwords, stemming y n-gramas.\n2. Medir el impacto de cada paso en el vocabulario y los tokens.","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Carga el corpus\ndf = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\", encoding='utf-8')\ndf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:20.801772Z","iopub.execute_input":"2025-11-17T16:05:20.802255Z","iopub.status.idle":"2025-11-17T16:05:21.550350Z","shell.execute_reply.started":"2025-11-17T16:05:20.802227Z","shell.execute_reply":"2025-11-17T16:05:21.549441Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"                                                  review sentiment\n0      One of the other reviewers has mentioned that ...  positive\n1      A wonderful little production. <br /><br />The...  positive\n2      I thought this was a wonderful way to spend ti...  positive\n3      Basically there's a family where a little boy ...  negative\n4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n...                                                  ...       ...\n49995  I thought this movie did a down right good job...  positive\n49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n49997  I am a Catholic taught in parochial elementary...  negative\n49998  I'm going to have to disagree with the previou...  negative\n49999  No one expects the Star Trek movies to be high...  negative\n\n[50000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>I thought this movie did a down right good job...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>I am a Catholic taught in parochial elementary...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>I'm going to have to disagree with the previou...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>No one expects the Star Trek movies to be high...</td>\n      <td>negative</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# Toma primera reseña del dataset y lo guarda en doc\ndoc = df.iloc[0]['review']\ndoc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:21.551859Z","iopub.execute_input":"2025-11-17T16:05:21.552119Z","iopub.status.idle":"2025-11-17T16:05:21.558355Z","shell.execute_reply.started":"2025-11-17T16:05:21.552098Z","shell.execute_reply":"2025-11-17T16:05:21.557371Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"# Didide texto en tokens simples, separados por espacios\n# doc.split()\n# Solo divide al texto por espacios ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:21.559503Z","iopub.execute_input":"2025-11-17T16:05:21.559848Z","iopub.status.idle":"2025-11-17T16:05:21.573822Z","shell.execute_reply.started":"2025-11-17T16:05:21.559827Z","shell.execute_reply":"2025-11-17T16:05:21.572996Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import re\n# Elemina etiqeutas HTML muy comunes en el dataset usando regex y quita puntacion especifica y divide tokens otra vez\n#doc_=re.sub(pattern='<.*?>', repl='', string=doc).replace('.', '').replace(',', '').replace('(', '').replace(')', '').replace('\"\"', '')\n#doc_.split()\n\n\n# Crea una funcion reusable para la limpieza de cualquier texto, no tokenitiza\ndef clean_text(doc):\n    return re.sub(pattern='<.*?>', repl='', string=doc).replace('.', '').replace(',', '').replace('(', '').replace(')', '').replace('\"\"', '')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:21.574790Z","iopub.execute_input":"2025-11-17T16:05:21.575431Z","iopub.status.idle":"2025-11-17T16:05:21.589472Z","shell.execute_reply.started":"2025-11-17T16:05:21.575398Z","shell.execute_reply":"2025-11-17T16:05:21.588504Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Aplica la funcion clean_text a la data\n# Prepara el corpus completo para: tokenizacion, stopwords, steaming/lematizacion/ construccion indice invertido y creacion TF-IDF\ndf['cleaned_review'] = df['review'].apply(clean_text)\nprint(df['cleaned_review'].head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:21.592038Z","iopub.execute_input":"2025-11-17T16:05:21.592535Z","iopub.status.idle":"2025-11-17T16:05:22.118928Z","shell.execute_reply.started":"2025-11-17T16:05:21.592507Z","shell.execute_reply":"2025-11-17T16:05:22.117885Z"}},"outputs":[{"name":"stdout","text":"0    One of the other reviewers has mentioned that ...\n1    A wonderful little production The filming tech...\n2    I thought this was a wonderful way to spend ti...\n3    Basically there's a family where a little boy ...\n4    Petter Mattei's \"Love in the Time of Money\" is...\n5    Probably my all-time favorite movie a story of...\n6    I sure would like to see a resurrection of a u...\n7    This show was an amazing fresh & innovative id...\n8    Encouraged by the positive comments about this...\n9    If you like original gut wrenching laughter yo...\nName: cleaned_review, dtype: object\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:22.119851Z","iopub.execute_input":"2025-11-17T16:05:22.120105Z","iopub.status.idle":"2025-11-17T16:05:22.127834Z","shell.execute_reply.started":"2025-11-17T16:05:22.120086Z","shell.execute_reply":"2025-11-17T16:05:22.126721Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from nltk.stem import porter\nstemmer = porter.PorterStemmer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:22.128895Z","iopub.execute_input":"2025-11-17T16:05:22.129256Z","iopub.status.idle":"2025-11-17T16:05:22.145948Z","shell.execute_reply.started":"2025-11-17T16:05:22.129225Z","shell.execute_reply":"2025-11-17T16:05:22.144930Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"## Normalizacion, Tokenizar y eliminar Stopwords\n\n\n","metadata":{}},{"cell_type":"code","source":"def tokenize_and_remove_stopwords(text):\n    # Tokenizacion\n    tokens = word_tokenize(text.lower()) # Normalizacion sencilla 1\n    \n    # Eliminar stopwords\n    stop_words = set(stopwords.words('english'))\n    \n    # Normalizacion sencilla 2: Aqui se filtran solo palabras alfabéticas\n    filtered_tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n    \n    return filtered_tokens\n\n# Aplicar tokenizacion y eliminacion de stopwords\ndf['tokens'] = df['cleaned_review'].apply(tokenize_and_remove_stopwords)\n\nprint(\"Tokens despues de stopwords - Primeras 2 revisiones:\")\nprint(df['tokens'].head(2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:05:22.146934Z","iopub.execute_input":"2025-11-17T16:05:22.147207Z","iopub.status.idle":"2025-11-17T16:06:11.065079Z","shell.execute_reply.started":"2025-11-17T16:05:22.147185Z","shell.execute_reply":"2025-11-17T16:06:11.064221Z"}},"outputs":[{"name":"stdout","text":"Tokens despues de stopwords - Primeras 2 revisiones:\n0    [one, reviewers, mentioned, watching, oz, epis...\n1    [wonderful, little, production, filming, techn...\nName: tokens, dtype: object\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## Stemming","metadata":{}},{"cell_type":"code","source":"def apply_stemming(tokens):\n    return [stemmer.stem(token) for token in tokens]\n\n# Aplicar stemming\ndf['stemmed_tokens'] = df['tokens'].apply(apply_stemming)\n\nprint(\"Tokens despues de stemming - Primeras 2 revisiones:\")\nprint(df['stemmed_tokens'].head(2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:06:11.065956Z","iopub.execute_input":"2025-11-17T16:06:11.066171Z","iopub.status.idle":"2025-11-17T16:07:43.306974Z","shell.execute_reply.started":"2025-11-17T16:06:11.066152Z","shell.execute_reply":"2025-11-17T16:07:43.305954Z"}},"outputs":[{"name":"stdout","text":"Tokens despues de stemming - Primeras 2 revisiones:\n0    [one, review, mention, watch, oz, episod, hook...\n1    [wonder, littl, product, film, techniqu, fashi...\nName: stemmed_tokens, dtype: object\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## Indice invertidos","metadata":{}},{"cell_type":"code","source":"def build_inverted_index(df):\n    inverted_index = {}\n    \n    for doc_id, tokens in enumerate(df['stemmed_tokens']):\n        for token in set(tokens):  # Usar set para evitar duplicados dentro del mismo documento\n            if token not in inverted_index:\n                inverted_index[token] = []\n            inverted_index[token].append(doc_id)\n    \n    return inverted_index\n\n# Construir indice invertido\ninverted_index = build_inverted_index(df)\n\nprint(\"Indice invertido - Primeros 5 terminos:\")\nfor i, (term, doc_ids) in enumerate(list(inverted_index.items())[:5]):\n    print(f\"{term}: aparece en {len(doc_ids)} documentos\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:07:43.308071Z","iopub.execute_input":"2025-11-17T16:07:43.308349Z","iopub.status.idle":"2025-11-17T16:07:47.883237Z","shell.execute_reply.started":"2025-11-17T16:07:43.308321Z","shell.execute_reply":"2025-11-17T16:07:47.882497Z"}},"outputs":[{"name":"stdout","text":"Indice invertido - Primeros 5 terminos:\nwell: aparece en 13595 documentos\nemerald: aparece en 13 documentos\nclassic: aparece en 3526 documentos\none: aparece en 28148 documentos\nhome: aparece en 3023 documentos\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Celda nueva - Ver la evolución completa del texto\nprint(\"=== Comparacion del texto===\")\nprint(\"\\n1. Texto original:\")\nprint(df.iloc[0]['review'])\n\n# print(\"\\n2. DESPUÉS DE clean_text():\")\n# print(df.iloc[0]['cleaned_review'])\n\n# print(\"\\n3. DESPUÉS DE tokenize_and_remove_stopwords():\")\n# print(df.iloc[0]['tokens'])\n\nprint(\"\\n4. Texto Final despues de procesamiento\")\nprint(df.iloc[0]['stemmed_tokens'])\n\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:07:47.883959Z","iopub.execute_input":"2025-11-17T16:07:47.884163Z","iopub.status.idle":"2025-11-17T16:07:47.889878Z","shell.execute_reply.started":"2025-11-17T16:07:47.884147Z","shell.execute_reply":"2025-11-17T16:07:47.889053Z"}},"outputs":[{"name":"stdout","text":"=== Comparacion del texto===\n\n1. Texto original:\nOne of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n\n4. Texto Final despues de procesamiento\n['one', 'review', 'mention', 'watch', 'oz', 'episod', 'hook', 'right', 'exactli', 'happen', 'meth', 'first', 'thing', 'struck', 'oz', 'brutal', 'unflinch', 'scene', 'violenc', 'set', 'right', 'word', 'go', 'trust', 'show', 'faint', 'heart', 'timid', 'show', 'pull', 'punch', 'regard', 'drug', 'sex', 'violenc', 'hardcor', 'classic', 'use', 'wordit', 'call', 'oz', 'nicknam', 'given', 'oswald', 'maximum', 'secur', 'state', 'penitentari', 'focus', 'mainli', 'emerald', 'citi', 'experiment', 'section', 'prison', 'cell', 'glass', 'front', 'face', 'inward', 'privaci', 'high', 'agenda', 'em', 'citi', 'home', 'manyaryan', 'muslim', 'gangsta', 'latino', 'christian', 'italian', 'irish', 'moreso', 'scuffl', 'death', 'stare', 'dodgi', 'deal', 'shadi', 'agreement', 'never', 'far', 'awayi', 'would', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'goe', 'show', 'would', 'dare', 'forget', 'pretti', 'pictur', 'paint', 'mainstream', 'audienc', 'forget', 'charm', 'forget', 'romanceoz', 'mess', 'around', 'first', 'episod', 'ever', 'saw', 'struck', 'nasti', 'surreal', 'could', 'say', 'readi', 'watch', 'develop', 'tast', 'oz', 'got', 'accustom', 'high', 'level', 'graphic', 'violenc', 'violenc', 'injustic', 'crook', 'guard', 'sold', 'nickel', 'inmat', 'kill', 'order', 'get', 'away', 'well', 'manner', 'middl', 'class', 'inmat', 'turn', 'prison', 'bitch', 'due', 'lack', 'street', 'skill', 'prison', 'experi', 'watch', 'oz', 'may', 'becom', 'comfort', 'uncomfort', 'viewingthat', 'get', 'touch', 'darker', 'side']\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"def contar_vocabulario_original(df):\n    # Terminos unicos antes del procesamiento\n    original_terms = set()\n    for review in df['review']:\n        tokens = word_tokenize(review.lower())\n        original_terms.update(tokens)\n    return len(original_terms)\n\ndef contar_vocabulario_final(df):\n    # Terminos unicos despues del procesamiento\n    stemmed_terms = set()\n    for tokens_list in df['stemmed_tokens']:\n        stemmed_terms.update(tokens_list)\n    return len(stemmed_terms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:07:47.890748Z","iopub.execute_input":"2025-11-17T16:07:47.890990Z","iopub.status.idle":"2025-11-17T16:07:47.905374Z","shell.execute_reply.started":"2025-11-17T16:07:47.890963Z","shell.execute_reply":"2025-11-17T16:07:47.904488Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Aplicar las funciones\nvocab_original = contar_vocabulario_original(df)\nvocab_final = contar_vocabulario_final(df)\n\nprint(\"=== COMPARACION VOCABULARIO ===\")\nprint(f\"Terminos antes del procesamiento: {vocab_original:,}\")\nprint(f\"Terminos después de todo el procesamiento: {vocab_final:,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:07:47.906284Z","iopub.execute_input":"2025-11-17T16:07:47.906629Z","iopub.status.idle":"2025-11-17T16:09:01.049195Z","shell.execute_reply.started":"2025-11-17T16:07:47.906603Z","shell.execute_reply":"2025-11-17T16:09:01.048318Z"}},"outputs":[{"name":"stdout","text":"=== COMPARACION VOCABULARIO ===\nTerminos antes del procesamiento: 164,024\nTerminos después de todo el procesamiento: 134,212\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"def contar_todos_terminos_original(df):\n    # Cuenta abosultamente todos los terminos del texto original\n    total_tokens = 0\n    for review in df['review']:\n        tokens = word_tokenize(review.lower())\n        total_tokens += len(tokens)\n    return total_tokens\n\ndef contar_todos_terminos_final(df):\n    # Cuenta absolutamente todos los terminos despues del preprocesamiento\n    total_tokens = 0\n    for tokens_list in df['stemmed_tokens']:\n        total_tokens += len(tokens_list)\n    return total_tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:09:01.051884Z","iopub.execute_input":"2025-11-17T16:09:01.052209Z","iopub.status.idle":"2025-11-17T16:09:01.057226Z","shell.execute_reply.started":"2025-11-17T16:09:01.052187Z","shell.execute_reply":"2025-11-17T16:09:01.056327Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# Aplicar las funciones\ntodos_original = contar_todos_terminos_original(df)\ntodos_final = contar_todos_terminos_final(df)\n\nprint(\"=== CONTEO DE TODOS LOS TERMINOS ===\")\nprint(f\"TODOS los terminos antes del procesamiento: {todos_original:,}\")\nprint(f\"TODOS los terminos después del procesamiento: {todos_final:,}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T16:09:01.057938Z","iopub.execute_input":"2025-11-17T16:09:01.058176Z","iopub.status.idle":"2025-11-17T16:10:12.661135Z","shell.execute_reply.started":"2025-11-17T16:09:01.058156Z","shell.execute_reply":"2025-11-17T16:10:12.660053Z"}},"outputs":[{"name":"stdout","text":"=== CONTEO DE TODOS LOS TERMINOS ===\nTODOS los terminos antes del procesamiento: 13,970,596\nTODOS los terminos después del procesamiento: 5,715,633\n","output_type":"stream"}],"execution_count":48}]}